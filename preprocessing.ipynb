{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_data():\n",
    "  # get flie list from the directory /data\n",
    "  file_list = os.listdir('data')\n",
    "  # create a file specific named dataframes for each file\n",
    "  for file in file_list:\n",
    "    globals()[file.split('.')[0]] = pd.read_pickle('data/' + file)\n",
    "\n",
    "load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(new_programmers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobplanet, jumpit, programmers, rocketpunch 순서\n",
    "# ======================================================\n",
    "# 회사명:    company_name        (name, companyName, company_name, company_name)\n",
    "# 직무명:    title               (title, title, title, job_title)\n",
    "# 경력:      career              (recruitment_text, [minCarrer, maxCarrer], career, experienceRequirements)\n",
    "# 기간:      date                (deadline_message, closedAt, period, validThrough(NaN인 경우 상시인듯))\n",
    "# 기술스택:  tech_stack           (skills, techStacks, reqired_skills, specialties)\n",
    "# 직무소개:  description          (primary_responsibility, responsibility, description, description(중복된 이름 가진 컬럼 존재))\n",
    "# 기업소개:  company_description  (introduction, serviceInfo, company['serviceName'], description(상기된 중복이름 컬럼 중 하나))\n",
    "# 자격요건:  required             (required_qualification, qualifications, requirement, requirement)\n",
    "# 우대사항:  preferred_skill      (preferred_skill, preferredRequirements, preferredExperience, 없음)\n",
    "# 복지및혜택: welfare             (benefit, welfares, additionalInformation, 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jp = jobplanet[['name', 'title', 'recruitment_text', 'deadline_message', 'skills', 'primary_responsibility', 'introduction', 'required_qualification', 'preferred_skill', 'benefit']]\n",
    "df_jp.columns = ['company_name', 'title', 'career', 'date', 'tech_stack', 'description', 'company_description', 'required', 'preferred_skill', 'welfare']\n",
    "\n",
    "jumpit['career_range'] = jumpit['minCareer'].astype(str) + '~' + jumpit['maxCareer'].astype(str)\n",
    "\n",
    "df_ju = jumpit[['companyName', 'title', 'career_range', 'closedAt', 'techStacks', 'responsibility', 'serviceInfo', 'qualifications', 'preferredRequirements', 'welfares']]\n",
    "df_ju.columns = ['company_name', 'title', 'career', 'date', 'tech_stack', 'description', 'company_description', 'required', 'preferred_skill', 'welfare']\n",
    "\n",
    "new_programmers['company_desc'] = new_programmers['company'].apply(lambda x: x['serviceName'])\n",
    "\n",
    "df_pr = new_programmers[['company_name', 'title', 'career', 'period', 'technicalTags', 'description', 'company_desc', 'requirement', 'preferredExperience', 'additionalInformation']]\n",
    "df_pr.columns = ['company_name', 'title', 'career', 'date', 'tech_stack', 'description', 'company_description', 'required', 'preferred_skill', 'welfare']\n",
    "\n",
    "rocketpunch_full.columns = ['company_id', 'company_name', 'company_desc', 'job_id', 'job_title','job_info', 'job_date', '@context', '@type', 'datePosted','description', 'hiringOrganization', 'title', 'url', 'jobLocation','employmentType', 'experienceRequirements', 'occupationalCategory','requirement', 'specialties', 'validThrough', 'baseSalary','jobLocationType']\n",
    "\n",
    "df_rp = rocketpunch_full[['company_name', 'job_title', 'experienceRequirements', 'validThrough', 'specialties', 'description', 'company_desc', 'requirement']]\n",
    "df_rp.columns = ['company_name', 'title', 'career', 'date', 'tech_stack', 'description', 'company_description', 'required']\n",
    "df_rp['preferred_skill'] = np.nan\n",
    "df_rp['welfare'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_jp.head(10))\n",
    "display(df_ju.head(2))\n",
    "display(df_pr.head(2))\n",
    "display(df_rp.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_rp['description'].apply(lambda x: list(filter(None, re.split(r'(?=[\\)\\\\|#])', x.replace('\\n', ' ')))))[7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "db_info = {}\n",
    "with open(\"db_info.env\", \"r\") as f:\n",
    "  for line in f:\n",
    "    key, value = line.strip().split(\"=\")\n",
    "    db_info[key] = value\n",
    "\n",
    "# connect to db\n",
    "conn = pymysql.connect(\n",
    "  host=db_info[\"DB_HOST\"],\n",
    "  user=db_info[\"DB_USER\"],\n",
    "  password=db_info[\"DB_PASS\"],\n",
    "  db=db_info[\"DB_NAME\"],\n",
    "  charset='utf8'\n",
    ")\n",
    "cur = conn.cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table\n",
    "CREATE TABLE job_data_t(\n",
    "  id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "\tjob_site_code INT,\n",
    "\tcompany_name VARCHAR(50),\n",
    "\ttitle VARCHAR(100),\n",
    "\tcareer VARCHAR(50),\n",
    "\tdate_until DATE,\n",
    "\ttech_stack VARCHAR(150),\n",
    "\tdescription TEXT,\n",
    "\tcompany_description TEXT,\n",
    "\trequired TEXT\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "from datetime import date\n",
    "import random\n",
    "\n",
    "faker = Faker()\n",
    "# Generate dummy data\n",
    "dummy_data = []\n",
    "for _ in range(10000):\n",
    "  row = (\n",
    "    random.randint(1, 4),  # First column as integer ranging from 1 to 4\n",
    "    faker.company(),  # Second column as company name\n",
    "    faker.job(),  # Third column as job title\n",
    "    random.randint(0,10), # Fourth column as career\n",
    "    str(faker.date_between(start_date='today', end_date='+1y')),  # Fifth column as date\n",
    "    str(faker.random_elements(elements=('Python', 'Java', 'C++', 'JavaScript', 'Ruby', 'PHP', 'Swift', 'Kotlin', 'Go', 'Rust', 'Cobol', 'Fortran', 'Scala', 'Perl', 'R', 'Dart', 'TypeScript', 'HTML', 'CSS', 'SQL', 'NoSQL', 'MongoDB', 'PostgreSQL', 'MySQL', 'MariaDB', 'SQLite', 'Oracle', 'MS SQL', 'Redis', 'Elasticsearch', 'Kafka', 'RabbitMQ', 'ActiveMQ', 'ZeroMQ', 'NATS', 'Kubernetes', 'Docker', 'Vagrant', 'Ansible', 'Puppet', 'Chef', 'Salt', 'Jenkins', 'CircleCI', 'TravisCI', 'GitLabCI', 'GitHubActions', 'AWS', 'GCP', 'Azure', 'IBM Cloud', 'Alibaba Cloud', 'Oracle Cloud', 'DigitalOcean', 'Heroku', 'Netlify', 'Vercel', 'Firebase', 'Cloudflare', 'Nginx', 'Apache', 'IIS', 'Tomcat', 'Jetty', 'Node.js', 'Express.js', 'Hadoop', 'Spark'), length=3, unique=True)),\n",
    "    faker.text(),  # Seventh column as description\n",
    "    faker.text(),  # Eighth column as company description\n",
    "    faker.text(),  # Ninth column as required qualification\n",
    "  )\n",
    "  dummy_data.append(row)\n",
    "\n",
    "# insert dummy data\n",
    "for data in dummy_data:\n",
    "  cur.execute(\"INSERT INTO job_data_t (job_site_code, company_name, title, career, date_until, tech_stack, description, company_description, required) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\", data)\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# If you haven't downloaded the stopwords from NLTK, you need to do so\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# read description column from db\n",
    "# cur.execute(\"SELECT description FROM job_data\")\n",
    "# rows = cur.fetchall()\n",
    "\n",
    "# count words\n",
    "word_count = Counter()\n",
    "for row in rows:\n",
    "  word_count.update(re.findall(r'\\w+', row[0].lower()))\n",
    "\n",
    "# get the list of stopwords in English\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# remove stopwords\n",
    "for w in list(word_count):  # use list to avoid 'dictionary changed size during iteration' error\n",
    "  if w in stop_words:\n",
    "    del word_count[w]\n",
    "\n",
    "# get the word and count by descending order\n",
    "for w in word_count.most_common():\n",
    "  print(w)\n",
    "\n",
    "\n",
    "# draw a word cloud\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_count)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "  DROP TABLE IF EXISTS job_data;\n",
    "  \"\"\"\n",
    "sql2 = \"\"\"\n",
    "  SELECT * FROM job_data;\n",
    "  \"\"\"\n",
    "cur.execute(sql)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DE31-1st-text_mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
